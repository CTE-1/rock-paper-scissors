{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1bdae0f",
      "metadata": {
        "id": "e1bdae0f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eaf14c9",
      "metadata": {
        "id": "0eaf14c9"
      },
      "outputs": [],
      "source": [
        "dataset, dataset_info = tfds.load(\n",
        "    name='rock_paper_scissors',\n",
        "    data_dir='tmp',\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "dataset_train = dataset['train']\n",
        "dataset_test = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aefca20",
      "metadata": {
        "id": "0aefca20"
      },
      "outputs": [],
      "source": [
        "train_size = dataset_info.splits['train'].num_examples\n",
        "test_size = dataset_info.splits['test'].num_examples\n",
        "dataset_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "print('dataset name:', dataset_info.name)\n",
        "print('train dataset:', dataset_train)\n",
        "print('test dataset:', dataset_test)\n",
        "print('train dataset size:', train_size)\n",
        "print('test dataset size:', test_size)\n",
        "print('number of classes in train and test dataset:', dataset_classes, dataset_info.features['label'].names)\n",
        "print('shape of images in train and test dataset:', dataset_info.features['image'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69250a81",
      "metadata": {
        "id": "69250a81"
      },
      "outputs": [],
      "source": [
        "def plot_image(n=1):\n",
        "    for image, label in dataset_train.take(n):\n",
        "        image = image.numpy()\n",
        "        label = label.numpy()\n",
        "\n",
        "    image_label = dataset_info.features['label'].int2str(label)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(image_label)\n",
        "    plt.colorbar()\n",
        "    \n",
        "plot_image(5)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f89c41",
      "metadata": {
        "id": "22f89c41"
      },
      "outputs": [],
      "source": [
        "def plot_dataset(dataset, num=5):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plot_index = 0\n",
        "    for image, label in dataset.take(num):\n",
        "        image = image.numpy()\n",
        "        label = label.numpy()\n",
        "        \n",
        "        image_label = dataset_info.features['label'].int2str(label)\n",
        "        \n",
        "        plot_index+=1\n",
        "        plt.subplot(3, 5, plot_index)\n",
        "        plt.title(image_label)\n",
        "        plt.imshow(image)\n",
        "\n",
        "plot_dataset(dataset_train, 15)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5ab598",
      "metadata": {
        "id": "cb5ab598"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "image_size = 64\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (image_size, image_size))\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "dataset_train = dataset_train.map(format_image)\n",
        "dataset_test = dataset_test.map(format_image)\n",
        "\n",
        "# Explore preprocessed training dataset images.\n",
        "plot_dataset(dataset_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c844149",
      "metadata": {
        "id": "4c844149"
      },
      "outputs": [],
      "source": [
        "def image_transpose(image):\n",
        "    rand = tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) \n",
        "    image = tf.cond(rand < 0.5, \n",
        "                    lambda: tf.identity(image), \n",
        "                    lambda: tf.image.transpose(image)) \n",
        "    return image\n",
        "\n",
        "def image_flip(image: tf.Tensor) -> tf.Tensor:\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    return image\n",
        "\n",
        "def image_rotate(image):\n",
        "    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    rand = tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) \n",
        "    def random_rotate(image):\n",
        "        image = tfa.image.rotate(\n",
        "            image, tf.random.uniform(shape=[], minval=0 * np.pi / 180, maxval=360 * np.pi / 180, dtype=tf.float32))\n",
        "        return image\n",
        "    \n",
        "    image = tf.cond(rand < 0.5, \n",
        "                    lambda: tf.identity(image), \n",
        "                    lambda: random_rotate(image)) \n",
        "    return image  \n",
        "\n",
        "def image_color(image: tf.Tensor) -> tf.Tensor:\n",
        "    image = tf.image.random_saturation(image, lower=0.5, upper=3)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1)\n",
        "    image = tf.image.random_hue(image, max_delta=0.03)\n",
        "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
        "    return image\n",
        "\n",
        "def image_inversion(image: tf.Tensor) -> tf.Tensor:\n",
        "    rand = tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "    image = tf.cond(rand < 0.8, \n",
        "                    lambda: tf.identity(image), \n",
        "                    lambda: tf.math.add(tf.math.multiply(image, -1), 1))\n",
        "    return image\n",
        "\n",
        "def image_zoom(image: tf.Tensor, min_zoom=0.8, max_zoom=1.0) -> tf.Tensor:\n",
        "    image_width, image_height, image_colors = image.shape\n",
        "    crop_size = (image_width, image_height)\n",
        "\n",
        "    # Generate crop settings, ranging from a 1% to 20% crop.\n",
        "    scales = list(np.arange(min_zoom, max_zoom, 0.01))\n",
        "    boxes = np.zeros((len(scales), 4))\n",
        "\n",
        "    for i, scale in enumerate(scales):\n",
        "        x1 = y1 = 0.5 - (0.5 * scale)\n",
        "        x2 = y2 = 0.5 + (0.5 * scale)\n",
        "        boxes[i] = [x1, y1, x2, y2]\n",
        "\n",
        "    def random_crop(img):\n",
        "        # Create different crops for an image\n",
        "        crops = tf.image.crop_and_resize(\n",
        "            [img],\n",
        "            boxes=boxes,\n",
        "            box_indices=np.zeros(len(scales)),\n",
        "            crop_size=crop_size\n",
        "        )\n",
        "        # Return a random crop\n",
        "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
        "\n",
        "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "\n",
        "    # Only apply cropping 50% of the time\n",
        "    return tf.cond(choice < 0.5, lambda: image, lambda: random_crop(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ba7c27",
      "metadata": {
        "id": "38ba7c27"
      },
      "outputs": [],
      "source": [
        "def augment_data(image, label):\n",
        "    image = image_flip(image)\n",
        "    image = image_color(image)\n",
        "    image = image_zoom(image)\n",
        "    image = image_transpose(image)\n",
        "    image = image_inversion(image)\n",
        "    image = image_rotate(image)\n",
        "    return image, label\n",
        "\n",
        "dataset_train_augmented = dataset_train.map(augment_data)\n",
        "\n",
        "plot_dataset(dataset_train_augmented)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f372bba2",
      "metadata": {
        "id": "f372bba2"
      },
      "outputs": [],
      "source": [
        "dataset_train_batches = dataset_train_augmented.shuffle(\n",
        "    buffer_size=train_size).batch(batch_size=batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "dataset_test_batches = dataset_test.batch(batch_size)\n",
        "\n",
        "print(dataset_train_batches)\n",
        "print(dataset_test_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ea48f02",
      "metadata": {
        "id": "2ea48f02"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Convolution2D(input_shape=(image_size, image_size, 3), filters=64, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Convolution2D(input_shape=(image_size, image_size, 3), filters=64, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Convolution2D(input_shape=(image_size, image_size, 3), filters=128, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Convolution2D(input_shape=(image_size, image_size, 3), filters=128, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=512, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(units=dataset_classes, activation=tf.keras.activations.softmax)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92741d63",
      "metadata": {
        "id": "92741d63"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e81f02f",
      "metadata": {
        "id": "3e81f02f",
        "outputId": "382e326a-7ffe-497f-f8cd-f1f8c48f36aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "steps_per_epoch: 39\n",
            "validation_steps: 5\n"
          ]
        }
      ],
      "source": [
        "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=rmsprop_optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = test_size // batch_size\n",
        "\n",
        "print('steps_per_epoch:', steps_per_epoch)\n",
        "print('validation_steps:', validation_steps)\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc37b404",
      "metadata": {
        "id": "cc37b404"
      },
      "outputs": [],
      "source": [
        "training_history = model.fit(x=dataset_train_batches.repeat(),\n",
        "                             validation_data=dataset_test_batches.repeat(),\n",
        "                             epochs=15, \n",
        "                             steps_per_epoch=steps_per_epoch,\n",
        "                             validation_steps=validation_steps,\n",
        "                             callbacks=[early_stopping],\n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41df674",
      "metadata": {
        "id": "c41df674"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(training_history):\n",
        "    loss = training_history.history['loss']\n",
        "    val_loss = training_history.history['val_loss']\n",
        "\n",
        "    accuracy = training_history.history['accuracy']\n",
        "    val_accuracy = training_history.history['val_accuracy']\n",
        "\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('Training and Test Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(loss, label='Training set')\n",
        "    plt.plot(val_loss, label='Test set', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Training and Test Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.plot(accuracy, label='Training set')\n",
        "    plt.plot(val_accuracy, label='Test set', linestyle='--')\n",
        "    plt.legend()\n",
        "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(training_history)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde777ca",
      "metadata": {
        "id": "dde777ca"
      },
      "outputs": [],
      "source": [
        "train_loss, train_accuracy = model.evaluate(dataset_train.batch(batch_size).take(train_size))\n",
        "test_loss, test_accuracy = model.evaluate(dataset_test.batch(batch_size).take(test_size))\n",
        "\n",
        "print('Training Loss: ', train_loss)\n",
        "print('Training Accuracy: ', train_accuracy)\n",
        "print('Test Loss: ', test_loss)\n",
        "print('Test Accuracy: ', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16df665c",
      "metadata": {
        "id": "16df665c"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "with open('quant_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52cfd27",
      "metadata": {
        "id": "f52cfd27"
      },
      "outputs": [],
      "source": [
        "model.save_weights('my_model_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22a79732",
      "metadata": {
        "id": "22a79732"
      },
      "outputs": [],
      "source": [
        "model.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d06b537",
      "metadata": {
        "id": "8d06b537"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "training_rock.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}